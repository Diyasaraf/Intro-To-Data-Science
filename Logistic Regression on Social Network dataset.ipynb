{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5cd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07426522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Diya\\\\Downloads\\\\Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9c19c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a12a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [1, 2, 3]].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ead7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.iloc[:, 4].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9519c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12bc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_mapping = {\"Male\": 0, \"Female\": 1}\n",
    "X_train[:, 0] = np.vectorize(gender_mapping.get)(X_train[:, 0])\n",
    "X_test[:, 0] = np.vectorize(gender_mapping.get)(X_test[:, 0])\n",
    "Y_train = Y_train.astype(np.float64)\n",
    "Y_test = Y_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365fb267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train :  (280, 3)\n",
      "Shape of Y_train :  (280,)\n",
      "Shape of X_test :  (120, 3)\n",
      "Shape of Y_test :  (120,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train : \", X_train.shape)\n",
    "print(\"Shape of Y_train : \", Y_train.shape)\n",
    "print(\"Shape of X_test : \", X_test.shape)\n",
    "print(\"Shape of Y_test : \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a5e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.astype(np.float64)\n",
    "X_test= X_test.astype(np.float64)\n",
    "Y_train= Y_train.astype(np.float64)\n",
    "Y_test= Y_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35711aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z_exp = np.exp(np.array(z, dtype=np.float64))\n",
    "    return 1 / (1 + z_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd75712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    for _ in range(iterations):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        theta -= alpha * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb19abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_train_bias= X_train_bias.astype(np.float64)\n",
    "theta = np.zeros(X_train_bias.shape[1]).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888a6734",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "theta = gradient_descent(X_train_bias, Y_train, theta, alpha, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef376df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(X_train, X_test, Y_train, Y_test):\n",
    "    models = {\n",
    "        \"Raw Data\": LogisticRegression(random_state=42),\n",
    "        \"Normalization\": LogisticRegression(random_state=42),\n",
    "        \"Standardization\": LogisticRegression(random_state=42),\n",
    "    }\n",
    "\n",
    "    scalers = {\n",
    "        \"Raw Data\": None,\n",
    "        \"Normalization\": MinMaxScaler(),\n",
    "        \"Standardization\": StandardScaler(),\n",
    "    }\n",
    "\n",
    "    for key in models:\n",
    "        scaler = scalers[key]\n",
    "        X_train_scaled = X_train.astype(float) if scaler is None else scaler.fit_transform(X_train)\n",
    "        X_test_scaled = X_test.astype(float) if scaler is None else scaler.transform(X_test)\n",
    "\n",
    "        # Logistic Regression from scratch\n",
    "        h_scratch = sigmoid(np.dot(np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled], theta))\n",
    "        y_pred_scratch = np.round(h_scratch)\n",
    "        acc = accuracy_score(Y_test, y_pred_scratch)\n",
    "        # Logistic Regression using sklearn\n",
    "        model = models[key]\n",
    "        model.fit(X_train_scaled, Y_train)\n",
    "        y_pred_sklearn = model.predict(X_test_scaled)\n",
    "        acc_sklearn = accuracy_score(Y_test, y_pred_sklearn)\n",
    "\n",
    "        print(f\"{key} Accuracy (from scratch): {acc}\")\n",
    "        print(f\"{key} Accuracy (sklearn): {acc_sklearn}\")\n",
    "        print( y_pred_scratch)\n",
    "        print( y_pred_sklearn)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc0aeb92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Accuracy (from scratch): 0.39166666666666666\n",
      "Raw Data Accuracy (sklearn): 0.6083333333333333\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Normalization Accuracy (from scratch): 0.39166666666666666\n",
      "Normalization Accuracy (sklearn): 0.8416666666666667\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Standardization Accuracy (from scratch): 0.6416666666666667\n",
      "Standardization Accuracy (sklearn): 0.8583333333333333\n",
      "[0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diya\\AppData\\Local\\Temp\\ipykernel_5736\\388001998.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  z_exp = np.exp(np.array(z, dtype=np.float64))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa86b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all three cases, sklearn gives the most accurate predictions\n",
    "#Standardization and Normalization are important to get accurate results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
